// lib/utils/async-db-writer.ts
/**
 * ğŸš€ ë¹„ë™ê¸° DB ë°°ì¹˜ ë¼ì´í„°
 * ì‹¤ì œ ê±°ë˜ì†Œì²˜ëŸ¼ ì£¼ë¬¸ ì²˜ë¦¬ì™€ DB ì €ì¥ì„ ë¶„ë¦¬
 * ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë°°ì¹˜ë¡œ DBì— ì €ì¥í•˜ì—¬ ì„±ëŠ¥ ìµœì í™”
 */

import { createClient } from '@supabase/supabase-js';

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
);

interface PendingOrderRecord {
  user_id: string;
  pair: string;
  side: string;
  order_type: string;
  price: number | null;
  amount: number;
  filled_amount: number;
  status: string;
  redis_order_id: string;
  created_at?: Date;
}

interface PendingTradeRecord {
  id: string;
  pair: string;
  buyer_order_id: string | null;
  seller_order_id: string | null;
  price: number;
  amount: number;
  side: string;
  source: string;
  buyer_fee?: number;
  seller_fee?: number;
  price_impact?: number | null;
  amm_reserves_before?: any;
  amm_reserves_after?: any;
  redis_trade_id?: string | null;
  executed_at?: Date;
}

export class AsyncDBWriter {
  private static instance: AsyncDBWriter;
  private orderQueue: PendingOrderRecord[] = [];
  private tradeQueue: PendingTradeRecord[] = [];
  private isProcessing = false;
  private batchSize = 100; // ë°°ì¹˜ í¬ê¸°
  private flushInterval = 1000; // 1ì´ˆë§ˆë‹¤ í”ŒëŸ¬ì‹œ
  private maxQueueSize = 10000; // ìµœëŒ€ í í¬ê¸°

  private constructor() {
    // ì£¼ê¸°ì ìœ¼ë¡œ ë°°ì¹˜ ì²˜ë¦¬
    setInterval(() => {
      this.flushBatches();
    }, this.flushInterval);
  }

  static getInstance(): AsyncDBWriter {
    if (!AsyncDBWriter.instance) {
      AsyncDBWriter.instance = new AsyncDBWriter();
    }
    return AsyncDBWriter.instance;
  }

  /**
   * ì£¼ë¬¸ ì´ë ¥ì„ íì— ì¶”ê°€ (ì¦‰ì‹œ ë°˜í™˜)
   */
  queueOrderHistory(orderData: PendingOrderRecord): void {
    if (this.orderQueue.length >= this.maxQueueSize) {
      console.warn('âš ï¸ Order queue full, forcing flush');
      this.flushBatches();
    }
    
    this.orderQueue.push({
      ...orderData,
      created_at: new Date()
    });
    
    console.log(`ğŸ“ Queued order: ${orderData.redis_order_id} (Queue: ${this.orderQueue.length})`);
  }

  /**
   * ê±°ë˜ ì´ë ¥ì„ íì— ì¶”ê°€ (ì¦‰ì‹œ ë°˜í™˜)
   */
  queueTradeHistory(tradeData: PendingTradeRecord): void {
    if (this.tradeQueue.length >= this.maxQueueSize) {
      console.warn('âš ï¸ Trade queue full, forcing flush');
      this.flushBatches();
    }
    
    this.tradeQueue.push({
      ...tradeData,
      executed_at: new Date()
    });
    
    console.log(`ğŸ“Š Queued trade: ${tradeData.id} (Queue: ${this.tradeQueue.length})`);
  }

  /**
   * ë°°ì¹˜ í”ŒëŸ¬ì‹œ (ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬)
   */
  private async flushBatches(): Promise<void> {
    if (this.isProcessing) return;
    if (this.orderQueue.length === 0 && this.tradeQueue.length === 0) return;

    this.isProcessing = true;
    const startTime = Date.now();

    try {
      // í˜„ì¬ í ë³µì‚¬ í›„ ì´ˆê¸°í™”
      const ordersToProcess = [...this.orderQueue];
      const tradesToProcess = [...this.tradeQueue];
      this.orderQueue = [];
      this.tradeQueue = [];

      console.log(`ğŸš€ Flushing batches: ${ordersToProcess.length} orders, ${tradesToProcess.length} trades`);

      // ì£¼ë¬¸ ë°°ì¹˜ ì²˜ë¦¬
      if (ordersToProcess.length > 0) {
        await this.batchInsertOrders(ordersToProcess);
      }

      // ê±°ë˜ ë°°ì¹˜ ì²˜ë¦¬
      if (tradesToProcess.length > 0) {
        await this.batchInsertTrades(tradesToProcess);
      }

      const duration = Date.now() - startTime;
      console.log(`âœ… Batch flush completed in ${duration}ms`);

    } catch (_error) {
      console.error('âŒ Batch flush error:', _error);
      // ì‹¤íŒ¨í•œ ê²½ìš° íì— ë‹¤ì‹œ ì¶”ê°€í•˜ì§€ ì•ŠìŒ (ì„±ëŠ¥ ìš°ì„ )
    } finally {
      this.isProcessing = false;
    }
  }

  /**
   * ì£¼ë¬¸ ë°°ì¹˜ ì‚½ì…
   */
  private async batchInsertOrders(orders: PendingOrderRecord[]): Promise<void> {
    try {
      // PostgreSQLì˜ ë°°ì¹˜ insert ì‚¬ìš©
      const { error } = await supabase
        .from('order_history')
        .insert(orders);

      if (error) {
        console.error('âŒ Batch order insert failed:', error);
        throw error;
      }

      console.log(`âœ… Batch inserted ${orders.length} orders`);
    } catch (_error) {
      console.error('âŒ Order batch insert error:', _error);
      throw _error;
    }
  }

  /**
   * ê±°ë˜ ë°°ì¹˜ ì‚½ì…
   */
  private async batchInsertTrades(trades: PendingTradeRecord[]): Promise<void> {
    try {
      // PostgreSQLì˜ ë°°ì¹˜ insert ì‚¬ìš©
      const { error } = await supabase
        .from('trade_history')
        .insert(trades);

      if (error) {
        console.error('âŒ Batch trade insert failed:', error);
        throw error;
      }

      console.log(`âœ… Batch inserted ${trades.length} trades`);
    } catch (_error) {
      console.error('âŒ Trade batch insert error:', _error);
      throw _error;
    }
  }

  /**
   * ê°•ì œ í”ŒëŸ¬ì‹œ (í…ŒìŠ¤íŠ¸ìš©)
   */
  async forceFlush(): Promise<void> {
    await this.flushBatches();
  }

  /**
   * í ìƒíƒœ ì¡°íšŒ
   */
  getQueueStatus() {
    return {
      orderQueue: this.orderQueue.length,
      tradeQueue: this.tradeQueue.length,
      isProcessing: this.isProcessing
    };
  }

  /**
   * ì„¤ì • ì—…ë°ì´íŠ¸
   */
  updateConfig(config: {
    batchSize?: number;
    flushInterval?: number;
    maxQueueSize?: number;
  }) {
    if (config.batchSize) this.batchSize = config.batchSize;
    if (config.flushInterval) this.flushInterval = config.flushInterval;
    if (config.maxQueueSize) this.maxQueueSize = config.maxQueueSize;
    
    console.log('âš™ï¸ AsyncDBWriter config updated:', {
      batchSize: this.batchSize,
      flushInterval: this.flushInterval,
      maxQueueSize: this.maxQueueSize
    });
  }
}