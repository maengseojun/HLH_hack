# 변동성 지표 산출 가이드

이 문서는 토큰의 가격 변동성을 계산하고 데이터를 추출하는 과정에 대한 인수인계 문서입니다.

## 1. 변동성(Volatility)의 정의

본 프로젝트에서 사용하는 변동성은 **실현 변동성(Realized Volatility, RV)** 모델을 따릅니다. 이는 특정 기간 동안의 자산 가격 움직임의 변동폭을 측정하는 통계적 지표입니다.

계산 과정은 다음과 같습니다.

1.  **시계열 데이터 수집**: Dune Analytics의 `prices.hour` 테이블에서 1시간 간격의 토큰 가격 데이터를 수집합니다.
2.  **로그 수익률 계산**: 연속된 두 시간의 가격(C_t, C_{t-1})을 이용하여 시간당 로그 수익률(log return) `r_t`를 계산합니다.
    -   `r_t = ln(C_t / C_{t-1})`
    -   로그 수익률을 사용하는 이유는 시간 가산(time-additive) 속성을 가지며, 가격 변화율을 정규분포에 가깝게 만들어 통계적 분석을 용이하게 하기 때문입니다.
3.  **실현 변동성 산출**: 설정된 기간(`LOOKBACK_DAYS`) 동안의 모든 시간당 로그 수익률의 제곱합에 제곱근을 취하여 최종 변동성을 계산합니다.
    -   `RV = sqrt(sum(r_t^2))`

이 지표는 과거 가격 데이터에 기반하여 실제 발생한 변동성을 측정하므로 '실현' 변동성이라고 부릅니다.

## 2. SQL 쿼리 구성 및 고려사항

Dune Analytics에서 변동성 데이터를 추출하기 위한 SQL 쿼리는 여러 CTE(Common Table Expressions)로 구조화되어 있습니다. 각 부분의 역할은 다음과 같습니다.

-   **`params`**: 변동성을 계산할 기간(예: 최근 7일)을 정의합니다. `now()` 함수를 기준으로 동적으로 시작과 끝 시간을 설정합니다.
-   **`universe`**: 분석할 토큰의 목록(`chain`, `contract`)을 정의하는 부분입니다. 이 목록을 수정하여 원하는 토큰들을 대상으로 쿼리를 실행할 수 있습니다.
-   **`grid`**: `generate_series` 함수를 사용하여 분석 기간 전체에 걸쳐 1시간 간격의 완전한 타임라인을 생성합니다. 이는 특정 시간에 가격 데이터가 없는 경우를 처리하기 위한 기준틀(scaffold) 역할을 합니다.
-   **`px`**: `universe`에 명시된 토큰들의 가격 정보를 `prices.hour` 테이블에서 가져옵니다. 체인 종류(EVM, Solana)에 따라 주소 형식이 다르므로, `CASE` 문을 사용하여 각기 다른 조인 조건을 적용합니다.
-   **`rets`**: `grid`와 `px`를 조인하고 `LAG` 윈도우 함수를 사용하여 이전 시간의 가격을 가져와 시간당 로그 수익률(`log_return`)을 계산합니다. 가격이 0이거나 NULL인 비정상적인 데이터는 계산에서 제외합니다.
-   **`rv`**: 토큰별로 그룹화하여 로그 수익률의 제곱합(`sum_sq_lr`)과 유효 데이터 개수(`n_lr`)를 계산합니다.
-   **최종 `SELECT`**:
    -   `rv` CTE의 결과를 바탕으로 최종 실현 변동성(`rv_7d_1h`)을 계산합니다.
    -   데이터 품질 모니터링을 위한 유효 바 비율(`ebr_7d_1h`)을 산출합니다.
    -   유효 데이터 개수(`n_lr`)가 설정된 최소 기준(`MIN_BARS`) 미만인 토큰은 노이즈로 간주하여 결과에서 제외합니다.
    -   결과를 변동성이 낮은 순으로 정렬하여 반환합니다.

## 3. 프로그래밍 및 도구 워크플로우

변동성 데이터를 추출하고 활용하는 전체 과정은 다음과 같은 단계로 이루어집니다.

1.  **1단계: 데이터 추출 (Dune Analytics)**
    -   **도구**: Dune Analytics 웹사이트 또는 API
    -   **프로세스**:
        1.  제공된 SQL 쿼리의 `universe` CTE에 분석하고자 하는 토큰 목록을 입력합니다.
        2.  Dune Analytics에서 쿼리를 실행합니다.
        3.  결과를 CSV 파일로 다운로드하거나 API를 통해 JSON 형태로 받아옵니다.

2.  **2단계: 데이터 처리 및 분석 (Python)**
    -   **도구**: Python, `pandas` 라이브러리
    -   **프로세스**:
        1.  Dune에서 추출한 데이터(CSV 등)를 `pandas`의 `DataFrame`으로 불러옵니다.
        2.  필요에 따라 추가적인 데이터 정제, 변환, 또는 다른 데이터와의 병합 작업을 수행합니다.
        3.  분석 결과를 바탕으로 리포트를 생성하거나 다음 단계로 전달할 데이터를 준비합니다.

3.  **3단계: 데이터 활용 (Backend/Database)**
    -   **도구**: PostgreSQL, FastAPI, 등 프로젝트의 백엔드 시스템
    -   **프로세스**:
        1.  Python으로 처리된 최종 변동성 데이터를 데이터베이스에 저장합니다.
        2.  API 엔드포인트를 통해 해당 데이터를 외부에 제공하거나, 다른 서비스에서 활용할 수 있도록 합니다.
